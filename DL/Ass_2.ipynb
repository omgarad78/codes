{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fRGY3TUZ-GP"
      },
      "source": [
        "### DL LAB 2A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HU2EOx01WXqT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1jgaZbEuWYUl"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
        "columns = ['letter', 'x-box', 'y-box', 'width', 'height', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar',\n",
        "           'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
        "data = pd.read_csv(url, names=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8a4BM7c39V2l"
      },
      "outputs": [],
      "source": [
        "# 2. Separate features and labels\n",
        "X = data.drop('letter', axis=1).values\n",
        "y = data['letter'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6j23oTLfWrED"
      },
      "outputs": [],
      "source": [
        "# 3. Encode labels (A-Z -> 0-25)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mFdOm1qKWzwg"
      },
      "outputs": [],
      "source": [
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m7J9a8xkW1W2"
      },
      "outputs": [],
      "source": [
        "# 5. Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwJggL1YW3Er",
        "outputId": "ec052211-1279-41b1-9efd-ae72137a6964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 6. Build the DNN model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(16,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(26, activation='softmax')  # 26 letters A-Z\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWA40Dr4W5FE",
        "outputId": "3151d52c-ad93-4b16-dc37-3cf6d2c82b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 0.1553 - val_accuracy: 0.9506\n",
            "Epoch 2/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.1571 - val_accuracy: 0.9488\n",
            "Epoch 3/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 0.1527 - val_accuracy: 0.9563\n",
            "Epoch 4/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.1544 - val_accuracy: 0.9500\n",
            "Epoch 5/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.1451 - val_accuracy: 0.9563\n",
            "Epoch 6/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.1353 - val_accuracy: 0.9613\n",
            "Epoch 7/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.1396 - val_accuracy: 0.9581\n",
            "Epoch 8/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.1344 - val_accuracy: 0.9556\n",
            "Epoch 9/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.1606 - val_accuracy: 0.9513\n",
            "Epoch 10/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.1466 - val_accuracy: 0.9550\n",
            "Epoch 11/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.1651 - val_accuracy: 0.9488\n",
            "Epoch 12/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.1536 - val_accuracy: 0.9563\n",
            "Epoch 13/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.1545 - val_accuracy: 0.9556\n",
            "Epoch 14/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9946 - val_loss: 0.1822 - val_accuracy: 0.9525\n",
            "Epoch 15/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.1870 - val_accuracy: 0.9456\n",
            "Epoch 16/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 0.1385 - val_accuracy: 0.9613\n",
            "Epoch 17/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.1467 - val_accuracy: 0.9588\n",
            "Epoch 18/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.1462 - val_accuracy: 0.9569\n",
            "Epoch 19/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.1647 - val_accuracy: 0.9550\n",
            "Epoch 20/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.1694 - val_accuracy: 0.9556\n",
            "Epoch 21/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.1588 - val_accuracy: 0.9513\n",
            "Epoch 22/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.1913 - val_accuracy: 0.9525\n",
            "Epoch 23/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.1580 - val_accuracy: 0.9556\n",
            "Epoch 24/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.1864 - val_accuracy: 0.9525\n",
            "Epoch 25/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.1407 - val_accuracy: 0.9625\n",
            "Epoch 26/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.1639 - val_accuracy: 0.9563\n",
            "Epoch 27/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.1657 - val_accuracy: 0.9538\n",
            "Epoch 28/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.1539 - val_accuracy: 0.9619\n",
            "Epoch 29/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.1922 - val_accuracy: 0.9481\n",
            "Epoch 30/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.1511 - val_accuracy: 0.9594\n",
            "Epoch 31/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.1564 - val_accuracy: 0.9581\n",
            "Epoch 32/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.1559 - val_accuracy: 0.9644\n",
            "Epoch 33/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.1795 - val_accuracy: 0.9544\n",
            "Epoch 34/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.1719 - val_accuracy: 0.9581\n",
            "Epoch 35/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.1619 - val_accuracy: 0.9581\n",
            "Epoch 36/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.1530 - val_accuracy: 0.9625\n",
            "Epoch 37/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.1615 - val_accuracy: 0.9556\n",
            "Epoch 38/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.2010 - val_accuracy: 0.9525\n",
            "Epoch 39/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.2030 - val_accuracy: 0.9525\n",
            "Epoch 40/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.1724 - val_accuracy: 0.9544\n",
            "Epoch 41/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.1850 - val_accuracy: 0.9519\n",
            "Epoch 42/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.1757 - val_accuracy: 0.9556\n",
            "Epoch 43/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.1549 - val_accuracy: 0.9594\n",
            "Epoch 44/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.1593 - val_accuracy: 0.9588\n",
            "Epoch 45/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1790 - val_accuracy: 0.9550\n",
            "Epoch 46/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.1955 - val_accuracy: 0.9531\n",
            "Epoch 47/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1870 - val_accuracy: 0.9519\n",
            "Epoch 48/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.1773 - val_accuracy: 0.9550\n",
            "Epoch 49/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.1811 - val_accuracy: 0.9563\n",
            "Epoch 50/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.1679 - val_accuracy: 0.9594\n",
            "Epoch 51/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.1603 - val_accuracy: 0.9556\n",
            "Epoch 52/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.2045 - val_accuracy: 0.9506\n",
            "Epoch 53/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.1923 - val_accuracy: 0.9556\n",
            "Epoch 54/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.1697 - val_accuracy: 0.9556\n",
            "Epoch 55/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.1640 - val_accuracy: 0.9588\n",
            "Epoch 56/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.1679 - val_accuracy: 0.9600\n",
            "Epoch 57/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.1752 - val_accuracy: 0.9588\n",
            "Epoch 58/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0318 - accuracy: 0.9919 - val_loss: 0.2069 - val_accuracy: 0.9519\n",
            "Epoch 59/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1892 - val_accuracy: 0.9538\n",
            "Epoch 60/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.1593 - val_accuracy: 0.9613\n",
            "Epoch 61/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1547 - val_accuracy: 0.9600\n",
            "Epoch 62/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1633 - val_accuracy: 0.9588\n",
            "Epoch 63/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.1758 - val_accuracy: 0.9575\n",
            "Epoch 64/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.2320 - val_accuracy: 0.9394\n",
            "Epoch 65/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.1998 - val_accuracy: 0.9569\n",
            "Epoch 66/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1767 - val_accuracy: 0.9556\n",
            "Epoch 67/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.1949 - val_accuracy: 0.9531\n",
            "Epoch 68/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.2037 - val_accuracy: 0.9506\n",
            "Epoch 69/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.2294 - val_accuracy: 0.9456\n",
            "Epoch 70/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.1810 - val_accuracy: 0.9538\n",
            "Epoch 71/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.2256 - val_accuracy: 0.9494\n",
            "Epoch 72/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.1908 - val_accuracy: 0.9569\n",
            "Epoch 73/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1903 - val_accuracy: 0.9538\n",
            "Epoch 74/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.1804 - val_accuracy: 0.9525\n",
            "Epoch 75/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.1795 - val_accuracy: 0.9581\n",
            "Epoch 76/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1928 - val_accuracy: 0.9575\n",
            "Epoch 77/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.2368 - val_accuracy: 0.9506\n",
            "Epoch 78/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.1719 - val_accuracy: 0.9606\n",
            "Epoch 79/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.2040 - val_accuracy: 0.9538\n",
            "Epoch 80/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.1591 - val_accuracy: 0.9650\n",
            "Epoch 81/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9613\n",
            "Epoch 82/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.2077 - val_accuracy: 0.9581\n",
            "Epoch 83/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.2495 - val_accuracy: 0.9506\n",
            "Epoch 84/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1817 - val_accuracy: 0.9569\n",
            "Epoch 85/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.1780 - val_accuracy: 0.9594\n",
            "Epoch 86/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.1766 - val_accuracy: 0.9625\n",
            "Epoch 87/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1908 - val_accuracy: 0.9606\n",
            "Epoch 88/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.2106 - val_accuracy: 0.9588\n",
            "Epoch 89/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.2227 - val_accuracy: 0.9544\n",
            "Epoch 90/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1843 - val_accuracy: 0.9606\n",
            "Epoch 91/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1776 - val_accuracy: 0.9588\n",
            "Epoch 92/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1790 - val_accuracy: 0.9606\n",
            "Epoch 93/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.1881 - val_accuracy: 0.9569\n",
            "Epoch 94/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.2258 - val_accuracy: 0.9513\n",
            "Epoch 95/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.1988 - val_accuracy: 0.9569\n",
            "Epoch 96/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.1908 - val_accuracy: 0.9600\n",
            "Epoch 97/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.2098 - val_accuracy: 0.9488\n",
            "Epoch 98/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.1823 - val_accuracy: 0.9588\n",
            "Epoch 99/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1717 - val_accuracy: 0.9613\n",
            "Epoch 100/100\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 6.5172e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9600\n"
          ]
        }
      ],
      "source": [
        "# 7. Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOXR5POVXAlE",
        "outputId": "93e13376-f172-4673-8427-332160246ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9585\n"
          ]
        }
      ],
      "source": [
        "# 8. Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlQ11mf3XQT1",
        "outputId": "ed1a6921-ba3c-48c0-9acb-56f99273a2ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save(\"DNN.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw25kXZtXC00",
        "outputId": "1994b7a1-cd69-4c4f-af57-36678f855687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9585\n",
            "Test Accuracy: 0.9585\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFX4ZQayXoRa",
        "outputId": "d61e6fea-ff95-456b-9e8b-fcbcc8e0057f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# 9. Make predictions (optional)\n",
        "y_pred = model.predict(X_test)\n",
        "predicted_labels = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBcPctkU_UdM",
        "outputId": "7b88ee9c-2bd1-46b0-b226-85f4313d1956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "--- Random Sample Test ---\n",
            "True Letter: P\n",
            "Predicted Letter: P\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def random_sample_predict(model, scaler, label_encoder, X_test, y_test):\n",
        "    # Pick a random index\n",
        "    idx = random.randint(0, len(X_test) - 1)\n",
        "\n",
        "    # Select random sample\n",
        "    sample = X_test[idx].reshape(1, -1)\n",
        "    true_label = np.argmax(y_test[idx])\n",
        "    true_letter = label_encoder.inverse_transform([true_label])[0]\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(sample)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "    predicted_letter = label_encoder.inverse_transform(predicted_class)[0]\n",
        "\n",
        "    print(f\"\\n--- Random Sample Test ---\")\n",
        "    print(f\"True Letter: {true_letter}\")\n",
        "    print(f\"Predicted Letter: {predicted_letter}\")\n",
        "\n",
        "# Call this function after model training\n",
        "random_sample_predict(model, scaler, label_encoder, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggxJX5bCZ3f-"
      },
      "source": [
        "### DL LAB 2B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXitG_WRAujV",
        "outputId": "164705f1-15b9-47fb-a0da-096cdfde67a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5/5 - 3s - 667ms/step - accuracy: 0.2000 - loss: 0.6958\n",
            "Epoch 2/20\n",
            "5/5 - 0s - 26ms/step - accuracy: 0.5000 - loss: 0.6915\n",
            "Epoch 3/20\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.9000 - loss: 0.6847\n",
            "Epoch 4/20\n",
            "5/5 - 0s - 30ms/step - accuracy: 0.9000 - loss: 0.6790\n",
            "Epoch 5/20\n",
            "5/5 - 0s - 25ms/step - accuracy: 0.9000 - loss: 0.6702\n",
            "Epoch 6/20\n",
            "5/5 - 0s - 13ms/step - accuracy: 1.0000 - loss: 0.6568\n",
            "Epoch 7/20\n",
            "5/5 - 0s - 28ms/step - accuracy: 1.0000 - loss: 0.6376\n",
            "Epoch 8/20\n",
            "5/5 - 0s - 28ms/step - accuracy: 1.0000 - loss: 0.6084\n",
            "Epoch 9/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.5669\n",
            "Epoch 10/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.5026\n",
            "Epoch 11/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.4084\n",
            "Epoch 12/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.3190\n",
            "Epoch 13/20\n",
            "5/5 - 0s - 13ms/step - accuracy: 1.0000 - loss: 0.2097\n",
            "Epoch 14/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.1371\n",
            "Epoch 15/20\n",
            "5/5 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.1244\n",
            "Epoch 16/20\n",
            "5/5 - 0s - 25ms/step - accuracy: 1.0000 - loss: 0.0723\n",
            "Epoch 17/20\n",
            "5/5 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0535\n",
            "Epoch 18/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.0297\n",
            "Epoch 19/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.0178\n",
            "Epoch 20/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.0147\n",
            "\n",
            "Review Sentiment: Positive (Score: 0.9385)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.0103)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.0103)\n",
            "\n",
            "Review Sentiment: Positive (Score: 0.9875)\n"
          ]
        }
      ],
      "source": [
        "# 1. Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# 2. Create a small custom dataset (manually for simplicity)\n",
        "texts = [\n",
        "    \"The movie was fantastic and thrilling\",\n",
        "    \"I hated the movie, it was boring and bad\",\n",
        "    \"An excellent movie with brilliant performances\",\n",
        "    \"The film was dull and too long\",\n",
        "    \"Loved the story and the acting was amazing\",\n",
        "    \"Terrible movie, complete waste of time\",\n",
        "    \"What a masterpiece, loved every moment\",\n",
        "    \"Worst movie ever, so disappointed\",\n",
        "    \"Absolutely stunning, a wonderful experience\",\n",
        "    \"I regret watching this movie, very bad\"\n",
        "]\n",
        "\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# 3. Tokenize the texts\n",
        "max_words = 1000\n",
        "max_len = 20\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# 4. Build the Model\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
        "    layers.Bidirectional(layers.LSTM(32)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 5. Compile Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the Model\n",
        "model.fit(padded_sequences, np.array(labels), epochs=20, batch_size=2, verbose=2)\n",
        "\n",
        "# 7. Real-time Prediction Function\n",
        "def predict_sentiment(review):\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    padded = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    pred = model.predict(padded, verbose=0)[0][0]\n",
        "    sentiment = \"Positive\" if pred >= 0.5 else \"Negative\"\n",
        "    print(f\"\\nReview Sentiment: {sentiment} (Score: {pred:.4f})\")\n",
        "\n",
        "# 8. Real-time Testing\n",
        "sample_review1 = \"The movie was fantastic! I really loved the performances.\"\n",
        "predict_sentiment(sample_review1)\n",
        "\n",
        "sample_review2 = \"The film was boring and too long. Not good at all.\"\n",
        "predict_sentiment(sample_review2)\n",
        "\n",
        "sample_review3 = \"I absolutely hated this movie. Worst experience ever.\"\n",
        "predict_sentiment(sample_review3)\n",
        "\n",
        "sample_review4 = \"An excellent masterpiece. Great story and acting.\"\n",
        "predict_sentiment(sample_review4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Rf5SzkDNtj",
        "outputId": "bef27cea-6221-410a-b8a1-3e7a914a1cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.7048 - loss: 0.5320 - val_accuracy: 0.8608 - val_loss: 0.3290\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9095 - loss: 0.2309 - val_accuracy: 0.8698 - val_loss: 0.3129\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9386 - loss: 0.1698 - val_accuracy: 0.8712 - val_loss: 0.3587\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9677 - loss: 0.0999 - val_accuracy: 0.8642 - val_loss: 0.3867\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9743 - loss: 0.0769 - val_accuracy: 0.8638 - val_loss: 0.4658\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.4940)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.2831)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.2314)\n",
            "\n",
            "Review Sentiment: Positive (Score: 0.9432)\n"
          ]
        }
      ],
      "source": [
        "# 1. Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# 2. Load the IMDB dataset (with raw text)\n",
        "imdb = keras.datasets.imdb\n",
        "\n",
        "# Set vocabulary size\n",
        "vocab_size = 10000\n",
        "\n",
        "# Load dataset (already preprocessed as integers)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# 3. Decode function to get back text\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(text_ints):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text_ints])\n",
        "\n",
        "# 4. Prepare data (pad sequences)\n",
        "maxlen = 200\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 5. Build model\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, 64, input_length=maxlen),\n",
        "    layers.Bidirectional(layers.LSTM(64)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 6. Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 7. Train model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# 8. Real-time testing function\n",
        "def predict_sentiment_text(model, review_text):\n",
        "    # 8.1 Preprocessing: convert review to integers\n",
        "    words = review_text.lower().split()\n",
        "    review_seq = []\n",
        "    for word in words:\n",
        "        idx = word_index.get(word, 2)  # 2 is for unknown words\n",
        "        review_seq.append(idx)\n",
        "\n",
        "    review_seq = pad_sequences([review_seq], maxlen=maxlen)\n",
        "\n",
        "    pred = model.predict(review_seq, verbose=0)[0][0]\n",
        "    sentiment = \"Positive\" if pred >= 0.5 else \"Negative\"\n",
        "    print(f\"\\nReview Sentiment: {sentiment} (Score: {pred:.4f})\")\n",
        "\n",
        "# 9. Real examples\n",
        "sample_review1 = \"The movie was fantastic! I really loved the performances.\"\n",
        "predict_sentiment_text(model, sample_review1)\n",
        "\n",
        "sample_review2 = \"The film was boring and too long. Not good at all.\"\n",
        "predict_sentiment_text(model, sample_review2)\n",
        "\n",
        "sample_review3 = \"it is so disappointing.\"\n",
        "predict_sentiment_text(model, sample_review3)\n",
        "\n",
        "sample_review4 = \"An excellent movie. Great direction and amazing acting!\"\n",
        "predict_sentiment_text(model, sample_review4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekyTq-yCEqms"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
